{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "AVV2e0XKbJeX"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Load CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-3Xbt0FfGfs"
   },
   "source": [
    "This walkthrough provides examples of how to use CSV data with TensorFlow.\n",
    "\n",
    "There are two main parts to this:\n",
    "\n",
    "1. **Loading the data off disk**\n",
    "2. **Pre-processing it into a form suitable for training.**\n",
    "\n",
    "We will work with data in memory, since the features set is quite small\n",
    "\n",
    "Topics covered:\n",
    "* Loading data from a csv\n",
    "* splitting data into training, validation and test sets\n",
    "* Handling mixed types of data\n",
    "* Normalizing data\n",
    "* Handling categorical features\n",
    "* storing and re loading models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import regularizers\n",
    "#from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B87Rd1SOUv02"
   },
   "source": [
    "## Basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GS-dBMpuYMnz",
    "outputId": "250008c3-2fa9-461c-82b0-8c319c5b9a23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SoldPr</th>\n",
       "      <th>Type</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Area</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>FullBaths</th>\n",
       "      <th>HalfBaths</th>\n",
       "      <th>BsmtBth</th>\n",
       "      <th>Beds</th>\n",
       "      <th>BsmtBeds</th>\n",
       "      <th>GarageSpaces</th>\n",
       "      <th>houseEra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>334098.750000</td>\n",
       "      <td>SFH</td>\n",
       "      <td>60062</td>\n",
       "      <td>1792</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>473088.750000</td>\n",
       "      <td>SFH</td>\n",
       "      <td>60201</td>\n",
       "      <td>2780</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>225779.312500</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>60077</td>\n",
       "      <td>1063</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>463601.414062</td>\n",
       "      <td>SFH</td>\n",
       "      <td>60077</td>\n",
       "      <td>1844</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>19A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7737</th>\n",
       "      <td>626275.000000</td>\n",
       "      <td>SFH</td>\n",
       "      <td>60025</td>\n",
       "      <td>2883</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SoldPr       Type    Zip  Area  Rooms  FullBaths  HalfBaths  \\\n",
       "423   334098.750000        SFH  60062  1792      7          2          0   \n",
       "3453  473088.750000        SFH  60201  2780      8          1          1   \n",
       "5359  225779.312500  Townhouse  60077  1063      5          1          1   \n",
       "1402  463601.414062        SFH  60077  1844      9          3          0   \n",
       "7737  626275.000000        SFH  60025  2883     10          4          0   \n",
       "\n",
       "     BsmtBth  Beds  BsmtBeds  GarageSpaces houseEra  \n",
       "423       No   3.0         0           2.0      19A  \n",
       "3453     Yes   5.0         0           2.0      19B  \n",
       "5359      No   2.0         0           0.0      19A  \n",
       "1402     Yes   4.0         0           2.5      19A  \n",
       "7737     Yes   5.0         0           3.0      19A  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://junwin.github.io/data/housepriceclean2.csv\"\n",
    "#housePrices=pd.read_csv('/content/housepriceclean2.csv').sample(frac=1)\n",
    "housePrices=pd.read_csv(url).sample(frac=1)\n",
    "housePrices.pop('ClosedDate')\n",
    "#housePrices.pop('YearBuilt')\n",
    "housePrices.head()\n",
    "\n",
    "#housePrices = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/housePrices/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "y6eKJbdMPZJT"
   },
   "outputs": [],
   "source": [
    "#housePrices = housePrices.loc[(housePrices['Zip'] == 60076) & (housePrices['Type'] == 'SFH')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoY69vs9Mazt"
   },
   "source": [
    "#Working with input data\r\n",
    "There one feature worth exploring is the year the propert was built, here, I am experimenting with changing the year to a range of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tgdT-LHJXpC5"
   },
   "outputs": [],
   "source": [
    "# save a copy\r\n",
    "#housePrices.to_csv('/content/housepriceclean2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nngEWwnpx6eJ",
    "outputId": "fbde5280-c3b1-4bbb-980e-576e52dc6ca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoldPr          float64\n",
       "Type             object\n",
       "Zip              object\n",
       "Area              int64\n",
       "Rooms             int64\n",
       "FullBaths         int64\n",
       "HalfBaths         int64\n",
       "BsmtBth          object\n",
       "Beds            float64\n",
       "BsmtBeds          int64\n",
       "GarageSpaces    float64\n",
       "houseEra         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housePrices['Zip'] = housePrices['Zip'].astype(str) \r\n",
    "housePrices.dtypes\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPhMIKlWmWo_",
    "outputId": "a58b4d6d-1627-4eb5-d1d4-870f3f21e89c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5988 train examples\n",
      "1498 validation examples\n",
      "1872 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(housePrices, test_size=0.2)\r\n",
    "train, val = train_test_split(train, test_size=0.2)\r\n",
    "print(len(train), 'train examples')\r\n",
    "print(len(val), 'validation examples')\r\n",
    "print(len(test), 'test examples')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "D8rCGIK1ZzKx"
   },
   "outputs": [],
   "source": [
    "housePrices_features = train.copy()\n",
    "housePrices_labels = housePrices_features.pop('SoldPr')\n",
    "housePrices_labels = housePrices_labels/100000\n",
    "\n",
    "val_features = val.copy()\n",
    "val_labels = val.pop('SoldPr')\n",
    "val_labels = val_labels/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VshL1mDKSf6",
    "outputId": "903aefe7-2f67-4a81-e5a4-a77f39f3c580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type             object\n",
      "Zip              object\n",
      "Area              int64\n",
      "Rooms             int64\n",
      "FullBaths         int64\n",
      "HalfBaths         int64\n",
      "BsmtBth          object\n",
      "Beds            float64\n",
      "BsmtBeds          int64\n",
      "GarageSpaces    float64\n",
      "houseEra         object\n",
      "dtype: object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(housePrices_features.dtypes)\r\n",
    "print(housePrices_labels.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urHOwpCDYtcI"
   },
   "source": [
    "Because of the different data types and ranges you can't simply stack the features into  NumPy array and pass it to a `keras.Sequential` model. Each column needs to be handled individually. \n",
    "\n",
    "As one option, you could preprocess your data offline (using any tool you like) to convert categorical columns to numeric columns, then pass the processed output to your TensorFlow model. The disadvantage to that approach is that if you save and export your model the preprocessing is not saved with it. The `experimental.preprocessing` layers avoid this problem because they're part of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bta4Sx0Zau5v"
   },
   "source": [
    "In this example, you'll build a model that implements the preprocessing logic using [Keras functional API](https://www.tensorflow.org/guide/keras/functional.ipynb). You could also do it by [subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n",
    "\n",
    "The functional API operates on \"symbolic\" tensors. Normal \"eager\" tensors have a value. In contrast these \"symbolic\" tensors do not. Instead they keep track of which operations are run on them, and build representation of the calculation, that you can run later. Here's a quick example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNS9lT7f6_U2"
   },
   "source": [
    "To build the preprocessing model, start by building a set of symbolic `keras.Input` objects, matching the names and data-types of the CSV columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WODe_1da3yw",
    "outputId": "b071fae0-6bcf-41cf-ef82-bb1f53db3e4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Type': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'Type')>,\n",
       " 'Zip': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'Zip')>,\n",
       " 'Area': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Area')>,\n",
       " 'Rooms': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Rooms')>,\n",
       " 'FullBaths': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'FullBaths')>,\n",
       " 'HalfBaths': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'HalfBaths')>,\n",
       " 'BsmtBth': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'BsmtBth')>,\n",
       " 'Beds': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Beds')>,\n",
       " 'BsmtBeds': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'BsmtBeds')>,\n",
       " 'GarageSpaces': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'GarageSpaces')>,\n",
       " 'houseEra': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'houseEra')>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in housePrices_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaheJFmymq8l"
   },
   "source": [
    "The first step in your preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPRC_E6rkp8D",
    "outputId": "34e0d34b-629c-4fdb-c4df-34000235156c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'normalization')>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(housePrices[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JoR45Uj712l"
   },
   "source": [
    "Collect all the symbolic preprocessing results, to concatenate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "M7jIJw5XntdN"
   },
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0Hryylyosfm"
   },
   "source": [
    "For the string inputs use the `preprocessing.StringLookup` function to map from strings to integer indices in a vocabulary. Next, use `preprocessing.CategoryEncoding` to convert the indexes into `float32` data appropriate for the model. \n",
    "\n",
    "The default settings for the `preprocessing.CategoryEncoding` layer create a one-hot vector for each input. A `layers.Embedding` would also work. See the [preprocessing layers guide](https://www.tensorflow.org/guide/keras/preprocessing_layers#quick_recipes) and [tutorial](../structured_data/preprocessing_layers.ipynb) for more on this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7f0HGorqTUL",
    "outputId": "afea5362-5d34-42b5-9eab-6d10fae51dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['60053', '60062', '60025', '60201', '60026', '60202', '60076',\n",
       "       '60077', '60091', '60002', '60203', '60029', '60067', '60625'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz=housePrices_features['Zip']\r\n",
    "xxx = zz.to_numpy()\r\n",
    "zz.unique()\r\n",
    "#asd = ['SFH','Duplex','Condo', 'Townhouse']\r\n",
    "#np.unique(xxx)\r\n",
    "#rslt_df = housePrices_features[housePrices_features['Type'] in asd] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "79fi1Cgan2YV"
   },
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "  \n",
    "  lookup = preprocessing.StringLookup(vocabulary=np.unique(housePrices_features[name]))\n",
    "  one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnhv0T7itnc7"
   },
   "source": [
    "With the collection of `inputs` and `processed_inputs`, you can concatenate all the preprocessed inputs together, and build a model that handles the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "XJRzUTe8ukXc",
    "outputId": "2e1628cc-06e2-4c63-8130-dc310f8d6f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "housePrices_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = housePrices_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNHxrNW8vdda"
   },
   "source": [
    "This `model` just contains the input preprocessing. You can run it to see what it does to your data. Keras models don't automatically convert Pandas `DataFrames` because it's not clear if it should be converted to one tensor or to a dictionary of tensors. So convert it to a dictionary of tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5YjdYyMEacwQ"
   },
   "outputs": [],
   "source": [
    "housePrices_features_dict = {name: np.array(value) \n",
    "                         for name, value in housePrices_features.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nKJYoPByada"
   },
   "source": [
    "Slice out the first training example and pass it to this preprocessing model, you see the numeric features and string one-hots all concatenated together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjnmU8PSv8T3",
    "outputId": "ae04ee9e-36e1-4d33-9200-1bed3b55aee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 41), dtype=float32, numpy=\n",
       "array([[-1.069, -1.6  , -1.248, -0.959, -2.167, -0.374, -1.24 ,  0.   ,\n",
       "         0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in housePrices_features_dict.items()}\n",
    "housePrices_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkBf4LvmzMDp"
   },
   "source": [
    "Now build the model on top of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "coIPtGaCzUV7"
   },
   "outputs": [],
   "source": [
    "def housePrices_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(128,activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dense(32,activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    #layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "  return model\n",
    "\n",
    "housePrices_model = housePrices_model(housePrices_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK5uBQQF2KbZ"
   },
   "source": [
    "When you train the model, pass the dictionary of features as `x`, and the label as `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpMHKYTqomAL",
    "outputId": "3c609ef9-abf0-4eb2-ae49-37c021b26abf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "188/188 [==============================] - 5s 15ms/step - loss: 11.2449 - mae: 2.2709 - val_loss: 3.1945 - val_mae: 0.9882\n",
      "Epoch 2/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2.3185 - mae: 0.9055 - val_loss: 2.7672 - val_mae: 0.8922\n",
      "Epoch 3/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.6055 - mae: 0.7845 - val_loss: 2.7126 - val_mae: 0.8899\n",
      "Epoch 4/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.7355 - mae: 0.7926 - val_loss: 2.5403 - val_mae: 0.8334\n",
      "Epoch 5/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.7563 - mae: 0.7814 - val_loss: 2.6481 - val_mae: 0.8572\n",
      "Epoch 6/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.6631 - mae: 0.7671 - val_loss: 2.5117 - val_mae: 0.8248\n",
      "Epoch 7/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.6677 - mae: 0.7686 - val_loss: 2.4507 - val_mae: 0.8114\n",
      "Epoch 8/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.5863 - mae: 0.7462 - val_loss: 2.6917 - val_mae: 0.8758\n",
      "Epoch 9/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.5075 - mae: 0.7454 - val_loss: 2.4049 - val_mae: 0.8264\n",
      "Epoch 10/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4865 - mae: 0.7441 - val_loss: 2.4154 - val_mae: 0.8099\n",
      "Epoch 11/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4827 - mae: 0.7355 - val_loss: 2.5063 - val_mae: 0.8109\n",
      "Epoch 12/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4896 - mae: 0.7354 - val_loss: 2.4346 - val_mae: 0.8245\n",
      "Epoch 13/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4833 - mae: 0.7503 - val_loss: 2.4636 - val_mae: 0.8082\n",
      "Epoch 14/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.6388 - mae: 0.7357 - val_loss: 2.3860 - val_mae: 0.8031\n",
      "Epoch 15/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.5042 - mae: 0.7264 - val_loss: 2.4306 - val_mae: 0.8191\n",
      "Epoch 16/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4353 - mae: 0.7248 - val_loss: 2.3872 - val_mae: 0.8078\n",
      "Epoch 17/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.5214 - mae: 0.7143 - val_loss: 2.4658 - val_mae: 0.8076\n",
      "Epoch 18/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.3642 - mae: 0.7053 - val_loss: 2.4095 - val_mae: 0.8152\n",
      "Epoch 19/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.5167 - mae: 0.7174 - val_loss: 2.4541 - val_mae: 0.8149\n",
      "Epoch 20/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.2348 - mae: 0.6945 - val_loss: 2.3939 - val_mae: 0.7973\n",
      "Epoch 21/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.3053 - mae: 0.7036 - val_loss: 2.4916 - val_mae: 0.8079\n",
      "Epoch 22/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.3471 - mae: 0.7178 - val_loss: 2.5272 - val_mae: 0.8096\n",
      "Epoch 23/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4263 - mae: 0.7258 - val_loss: 2.5333 - val_mae: 0.8198\n",
      "Epoch 24/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.3703 - mae: 0.7048 - val_loss: 2.5452 - val_mae: 0.8362\n",
      "Epoch 25/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.4403 - mae: 0.7182 - val_loss: 2.6134 - val_mae: 0.8167\n",
      "Epoch 26/500\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 1.3576 - mae: 0.7113 - val_loss: 2.4623 - val_mae: 0.8174\n",
      "Epoch 27/500\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.2778 - mae: 0.7023 - val_loss: 2.4780 - val_mae: 0.8068\n",
      "Epoch 28/500\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.2885 - mae: 0.6885 - val_loss: 2.6385 - val_mae: 0.8297\n",
      "Epoch 29/500\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.2607 - mae: 0.6972 - val_loss: 2.6925 - val_mae: 0.8306\n",
      "Epoch 30/500\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.3179 - mae: 0.6893 - val_loss: 2.5973 - val_mae: 0.8193\n",
      "Epoch 31/500\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.1986 - mae: 0.6750 - val_loss: 2.4876 - val_mae: 0.8089\n",
      "Epoch 32/500\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.3441 - mae: 0.7083 - val_loss: 2.5396 - val_mae: 0.8589\n",
      "Epoch 33/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1900 - mae: 0.6809 - val_loss: 2.5542 - val_mae: 0.8489\n",
      "Epoch 34/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.2278 - mae: 0.6914 - val_loss: 2.6321 - val_mae: 0.8828\n",
      "Epoch 35/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.3303 - mae: 0.7155 - val_loss: 2.5676 - val_mae: 0.8211\n",
      "Epoch 36/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.2495 - mae: 0.6764 - val_loss: 2.5131 - val_mae: 0.8046\n",
      "Epoch 37/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.3954 - mae: 0.7085 - val_loss: 2.6317 - val_mae: 0.8481\n",
      "Epoch 38/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.2182 - mae: 0.6882 - val_loss: 2.5743 - val_mae: 0.8669\n",
      "Epoch 39/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.3878 - mae: 0.7127 - val_loss: 2.5293 - val_mae: 0.8173\n",
      "Epoch 40/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.3420 - mae: 0.7006 - val_loss: 2.6104 - val_mae: 0.8316\n",
      "Epoch 41/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.2967 - mae: 0.6874 - val_loss: 2.6661 - val_mae: 0.8145\n",
      "Epoch 42/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.2375 - mae: 0.6664 - val_loss: 2.9327 - val_mae: 0.9401\n",
      "Epoch 43/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.2938 - mae: 0.6850 - val_loss: 2.6339 - val_mae: 0.8279\n",
      "Epoch 44/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.1614 - mae: 0.6723 - val_loss: 2.6732 - val_mae: 0.8717\n",
      "Epoch 45/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.2850 - mae: 0.6676 - val_loss: 2.7069 - val_mae: 0.8348\n",
      "Epoch 46/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.1881 - mae: 0.6669 - val_loss: 2.6598 - val_mae: 0.8230\n",
      "Epoch 47/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1712 - mae: 0.6509 - val_loss: 2.9198 - val_mae: 0.8487\n",
      "Epoch 48/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.2008 - mae: 0.6674 - val_loss: 2.6823 - val_mae: 0.8480\n",
      "Epoch 49/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.2069 - mae: 0.6753 - val_loss: 2.6354 - val_mae: 0.8292\n",
      "Epoch 50/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1043 - mae: 0.6447 - val_loss: 2.7364 - val_mae: 0.8239\n",
      "Epoch 51/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.2886 - mae: 0.6650 - val_loss: 2.8306 - val_mae: 0.8368\n",
      "Epoch 52/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1012 - mae: 0.6500 - val_loss: 2.8329 - val_mae: 0.8504\n",
      "Epoch 53/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0889 - mae: 0.6596 - val_loss: 2.8488 - val_mae: 0.8410\n",
      "Epoch 54/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1043 - mae: 0.6488 - val_loss: 2.7191 - val_mae: 0.8295\n",
      "Epoch 55/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1223 - mae: 0.6410 - val_loss: 2.9305 - val_mae: 0.8582\n",
      "Epoch 56/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1035 - mae: 0.6453 - val_loss: 2.9036 - val_mae: 0.8436\n",
      "Epoch 57/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0518 - mae: 0.6359 - val_loss: 2.7347 - val_mae: 0.8305\n",
      "Epoch 58/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1209 - mae: 0.6479 - val_loss: 2.7378 - val_mae: 0.8273\n",
      "Epoch 59/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0586 - mae: 0.6327 - val_loss: 2.8036 - val_mae: 0.8387\n",
      "Epoch 60/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.1286 - mae: 0.6434 - val_loss: 2.9755 - val_mae: 0.8571\n",
      "Epoch 61/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0499 - mae: 0.6404 - val_loss: 2.9391 - val_mae: 0.8913\n",
      "Epoch 62/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0458 - mae: 0.6336 - val_loss: 2.9316 - val_mae: 0.8442\n",
      "Epoch 63/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0399 - mae: 0.6319 - val_loss: 2.9527 - val_mae: 0.8402\n",
      "Epoch 64/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1416 - mae: 0.6684 - val_loss: 3.0803 - val_mae: 0.8882\n",
      "Epoch 65/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.1179 - mae: 0.6520 - val_loss: 3.1035 - val_mae: 0.8637\n",
      "Epoch 66/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0467 - mae: 0.6293 - val_loss: 2.8227 - val_mae: 0.8405\n",
      "Epoch 67/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9990 - mae: 0.6236 - val_loss: 3.0656 - val_mae: 0.8623\n",
      "Epoch 68/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0421 - mae: 0.6395 - val_loss: 2.9832 - val_mae: 0.8467\n",
      "Epoch 69/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0518 - mae: 0.6282 - val_loss: 3.0349 - val_mae: 0.8679\n",
      "Epoch 70/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9893 - mae: 0.6060 - val_loss: 2.9068 - val_mae: 0.8424\n",
      "Epoch 71/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9605 - mae: 0.6171 - val_loss: 2.9780 - val_mae: 0.8414\n",
      "Epoch 72/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9784 - mae: 0.6181 - val_loss: 3.0677 - val_mae: 0.8612\n",
      "Epoch 73/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0950 - mae: 0.6379 - val_loss: 2.9970 - val_mae: 0.8801\n",
      "Epoch 74/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9652 - mae: 0.6193 - val_loss: 3.1475 - val_mae: 0.8759\n",
      "Epoch 75/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9873 - mae: 0.6186 - val_loss: 3.0130 - val_mae: 0.8596\n",
      "Epoch 76/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0625 - mae: 0.6353 - val_loss: 2.9267 - val_mae: 0.8470\n",
      "Epoch 77/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9812 - mae: 0.6209 - val_loss: 3.1823 - val_mae: 0.8622\n",
      "Epoch 78/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1.0451 - mae: 0.6260 - val_loss: 3.1624 - val_mae: 0.8613\n",
      "Epoch 79/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9065 - mae: 0.5902 - val_loss: 3.1054 - val_mae: 0.8688\n",
      "Epoch 80/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8924 - mae: 0.5943 - val_loss: 3.2811 - val_mae: 0.8608\n",
      "Epoch 81/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9471 - mae: 0.6089 - val_loss: 3.1408 - val_mae: 0.8582\n",
      "Epoch 82/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9002 - mae: 0.5901 - val_loss: 3.0765 - val_mae: 0.8451\n",
      "Epoch 83/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.9676 - mae: 0.6142 - val_loss: 3.1710 - val_mae: 0.8760\n",
      "Epoch 84/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9659 - mae: 0.6125 - val_loss: 3.1378 - val_mae: 0.8506\n",
      "Epoch 85/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9281 - mae: 0.6018 - val_loss: 3.3153 - val_mae: 0.8685\n",
      "Epoch 86/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9280 - mae: 0.5980 - val_loss: 3.0995 - val_mae: 0.8736\n",
      "Epoch 87/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8864 - mae: 0.5924 - val_loss: 3.0946 - val_mae: 0.8648\n",
      "Epoch 88/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9484 - mae: 0.6138 - val_loss: 3.1809 - val_mae: 0.8547\n",
      "Epoch 89/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9682 - mae: 0.6019 - val_loss: 3.1991 - val_mae: 0.8530\n",
      "Epoch 90/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9289 - mae: 0.5952 - val_loss: 3.2347 - val_mae: 0.8605\n",
      "Epoch 91/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9224 - mae: 0.5986 - val_loss: 3.2390 - val_mae: 0.8651\n",
      "Epoch 92/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9494 - mae: 0.6040 - val_loss: 3.1142 - val_mae: 0.8674\n",
      "Epoch 93/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8678 - mae: 0.5748 - val_loss: 3.3706 - val_mae: 0.8692\n",
      "Epoch 94/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.9757 - mae: 0.6051 - val_loss: 3.2591 - val_mae: 0.9053\n",
      "Epoch 95/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8559 - mae: 0.5679 - val_loss: 3.2874 - val_mae: 0.8645\n",
      "Epoch 96/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8760 - mae: 0.5729 - val_loss: 3.1566 - val_mae: 0.8584\n",
      "Epoch 97/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8953 - mae: 0.5916 - val_loss: 3.3029 - val_mae: 0.8926\n",
      "Epoch 98/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8857 - mae: 0.5800 - val_loss: 3.1793 - val_mae: 0.8646\n",
      "Epoch 99/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.9678 - mae: 0.6010 - val_loss: 3.1989 - val_mae: 0.8634\n",
      "Epoch 100/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8414 - mae: 0.5650 - val_loss: 3.5140 - val_mae: 0.9080\n",
      "Epoch 101/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8793 - mae: 0.5826 - val_loss: 3.2888 - val_mae: 0.8627\n",
      "Epoch 102/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8392 - mae: 0.5756 - val_loss: 3.2456 - val_mae: 0.8633\n",
      "Epoch 103/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8773 - mae: 0.5771 - val_loss: 3.3333 - val_mae: 0.8727\n",
      "Epoch 104/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.9472 - mae: 0.5968 - val_loss: 3.5099 - val_mae: 0.8999\n",
      "Epoch 105/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.9044 - mae: 0.5936 - val_loss: 3.3146 - val_mae: 0.8724\n",
      "Epoch 106/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8785 - mae: 0.5790 - val_loss: 3.2463 - val_mae: 0.8782\n",
      "Epoch 107/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8568 - mae: 0.5626 - val_loss: 3.3465 - val_mae: 0.8710\n",
      "Epoch 108/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8548 - mae: 0.5637 - val_loss: 3.3624 - val_mae: 0.8732\n",
      "Epoch 109/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8432 - mae: 0.5679 - val_loss: 3.2762 - val_mae: 0.8618\n",
      "Epoch 110/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8722 - mae: 0.5902 - val_loss: 3.5944 - val_mae: 0.8841\n",
      "Epoch 111/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8483 - mae: 0.5630 - val_loss: 3.2414 - val_mae: 0.8766\n",
      "Epoch 112/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8467 - mae: 0.5720 - val_loss: 3.2116 - val_mae: 0.8830\n",
      "Epoch 113/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8633 - mae: 0.5782 - val_loss: 3.4347 - val_mae: 0.8780\n",
      "Epoch 114/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8426 - mae: 0.5701 - val_loss: 3.4757 - val_mae: 0.8899\n",
      "Epoch 115/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8928 - mae: 0.5851 - val_loss: 3.3230 - val_mae: 0.8916\n",
      "Epoch 116/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8247 - mae: 0.5665 - val_loss: 3.2991 - val_mae: 0.8588\n",
      "Epoch 117/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7949 - mae: 0.5549 - val_loss: 3.4973 - val_mae: 0.8804\n",
      "Epoch 118/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8538 - mae: 0.5647 - val_loss: 3.4814 - val_mae: 0.8912\n",
      "Epoch 119/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.9210 - mae: 0.5864 - val_loss: 3.4899 - val_mae: 0.8728\n",
      "Epoch 120/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8575 - mae: 0.5742 - val_loss: 3.3766 - val_mae: 0.8718\n",
      "Epoch 121/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8093 - mae: 0.5626 - val_loss: 3.4592 - val_mae: 0.8711\n",
      "Epoch 122/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7748 - mae: 0.5437 - val_loss: 3.3603 - val_mae: 0.8710\n",
      "Epoch 123/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8530 - mae: 0.5740 - val_loss: 3.6576 - val_mae: 0.8900\n",
      "Epoch 124/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8227 - mae: 0.5584 - val_loss: 3.2739 - val_mae: 0.8768\n",
      "Epoch 125/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8339 - mae: 0.5723 - val_loss: 3.4399 - val_mae: 0.8655\n",
      "Epoch 126/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7761 - mae: 0.5473 - val_loss: 3.3863 - val_mae: 0.8784\n",
      "Epoch 127/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8063 - mae: 0.5588 - val_loss: 3.3154 - val_mae: 0.8648\n",
      "Epoch 128/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8053 - mae: 0.5527 - val_loss: 3.6468 - val_mae: 0.8801\n",
      "Epoch 129/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7835 - mae: 0.5464 - val_loss: 3.5645 - val_mae: 0.8927\n",
      "Epoch 130/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7889 - mae: 0.5570 - val_loss: 3.4800 - val_mae: 0.8790\n",
      "Epoch 131/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7924 - mae: 0.5471 - val_loss: 3.5583 - val_mae: 0.8822\n",
      "Epoch 132/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7908 - mae: 0.5424 - val_loss: 3.2699 - val_mae: 0.8827\n",
      "Epoch 133/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8823 - mae: 0.5759 - val_loss: 3.5051 - val_mae: 0.8850\n",
      "Epoch 134/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7623 - mae: 0.5396 - val_loss: 3.6219 - val_mae: 0.8834\n",
      "Epoch 135/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8006 - mae: 0.5513 - val_loss: 3.4595 - val_mae: 0.8719\n",
      "Epoch 136/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7625 - mae: 0.5408 - val_loss: 3.7409 - val_mae: 0.9082\n",
      "Epoch 137/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7743 - mae: 0.5458 - val_loss: 3.6157 - val_mae: 0.8744\n",
      "Epoch 138/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7245 - mae: 0.5236 - val_loss: 3.4917 - val_mae: 0.8842\n",
      "Epoch 139/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7878 - mae: 0.5507 - val_loss: 3.3576 - val_mae: 0.8716\n",
      "Epoch 140/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7556 - mae: 0.5411 - val_loss: 3.3429 - val_mae: 0.8636\n",
      "Epoch 141/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7694 - mae: 0.5402 - val_loss: 3.9336 - val_mae: 0.9711\n",
      "Epoch 142/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.8543 - mae: 0.5847 - val_loss: 3.5626 - val_mae: 0.9055\n",
      "Epoch 143/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8280 - mae: 0.5593 - val_loss: 3.4224 - val_mae: 0.8809\n",
      "Epoch 144/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8297 - mae: 0.5687 - val_loss: 3.3090 - val_mae: 0.8754\n",
      "Epoch 145/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8174 - mae: 0.5602 - val_loss: 3.9208 - val_mae: 0.9053\n",
      "Epoch 146/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7262 - mae: 0.5249 - val_loss: 3.7429 - val_mae: 0.9067\n",
      "Epoch 147/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7741 - mae: 0.5377 - val_loss: 3.3856 - val_mae: 0.8837\n",
      "Epoch 148/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7185 - mae: 0.5249 - val_loss: 3.5118 - val_mae: 0.8921\n",
      "Epoch 149/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7528 - mae: 0.5409 - val_loss: 3.4000 - val_mae: 0.8797\n",
      "Epoch 150/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7477 - mae: 0.5324 - val_loss: 3.6757 - val_mae: 0.9209\n",
      "Epoch 151/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7544 - mae: 0.5462 - val_loss: 3.5210 - val_mae: 0.9060\n",
      "Epoch 152/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7718 - mae: 0.5445 - val_loss: 3.5863 - val_mae: 0.9051\n",
      "Epoch 153/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8140 - mae: 0.5481 - val_loss: 3.4723 - val_mae: 0.8825\n",
      "Epoch 154/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7244 - mae: 0.5285 - val_loss: 3.6114 - val_mae: 0.8880\n",
      "Epoch 155/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8102 - mae: 0.5593 - val_loss: 3.4921 - val_mae: 0.8995\n",
      "Epoch 156/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7760 - mae: 0.5459 - val_loss: 3.8031 - val_mae: 0.9739\n",
      "Epoch 157/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7918 - mae: 0.5583 - val_loss: 3.4494 - val_mae: 0.8871\n",
      "Epoch 158/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7575 - mae: 0.5322 - val_loss: 3.6193 - val_mae: 0.9117\n",
      "Epoch 159/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7190 - mae: 0.5243 - val_loss: 3.4365 - val_mae: 0.8834\n",
      "Epoch 160/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7402 - mae: 0.5356 - val_loss: 3.4377 - val_mae: 0.8840\n",
      "Epoch 161/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7404 - mae: 0.5340 - val_loss: 3.4682 - val_mae: 0.9016\n",
      "Epoch 162/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7167 - mae: 0.5247 - val_loss: 3.7960 - val_mae: 0.9550\n",
      "Epoch 163/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8341 - mae: 0.5620 - val_loss: 3.6816 - val_mae: 0.9179\n",
      "Epoch 164/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7408 - mae: 0.5309 - val_loss: 3.5736 - val_mae: 0.8916\n",
      "Epoch 165/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7123 - mae: 0.5211 - val_loss: 3.5553 - val_mae: 0.9222\n",
      "Epoch 166/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7540 - mae: 0.5407 - val_loss: 3.5071 - val_mae: 0.8965\n",
      "Epoch 167/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7130 - mae: 0.5194 - val_loss: 3.5161 - val_mae: 0.8892\n",
      "Epoch 168/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7482 - mae: 0.5367 - val_loss: 3.4570 - val_mae: 0.8967\n",
      "Epoch 169/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7490 - mae: 0.5350 - val_loss: 3.6391 - val_mae: 0.9050\n",
      "Epoch 170/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7819 - mae: 0.5408 - val_loss: 3.5099 - val_mae: 0.9126\n",
      "Epoch 171/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7103 - mae: 0.5192 - val_loss: 3.4234 - val_mae: 0.8910\n",
      "Epoch 172/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6972 - mae: 0.5180 - val_loss: 3.4811 - val_mae: 0.8933\n",
      "Epoch 173/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7322 - mae: 0.5253 - val_loss: 3.7213 - val_mae: 0.9193\n",
      "Epoch 174/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7000 - mae: 0.5164 - val_loss: 3.3746 - val_mae: 0.8827\n",
      "Epoch 175/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7134 - mae: 0.5228 - val_loss: 3.4964 - val_mae: 0.9047\n",
      "Epoch 176/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7490 - mae: 0.5356 - val_loss: 3.3886 - val_mae: 0.8950\n",
      "Epoch 177/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7312 - mae: 0.5376 - val_loss: 3.4315 - val_mae: 0.8921\n",
      "Epoch 178/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6796 - mae: 0.5145 - val_loss: 3.6861 - val_mae: 0.9091\n",
      "Epoch 179/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6995 - mae: 0.5159 - val_loss: 3.7883 - val_mae: 0.9264\n",
      "Epoch 180/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7279 - mae: 0.5268 - val_loss: 3.5976 - val_mae: 0.9098\n",
      "Epoch 181/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7215 - mae: 0.5190 - val_loss: 3.4935 - val_mae: 0.8979\n",
      "Epoch 182/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7308 - mae: 0.5302 - val_loss: 3.4278 - val_mae: 0.8890\n",
      "Epoch 183/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6889 - mae: 0.5028 - val_loss: 3.4339 - val_mae: 0.8879\n",
      "Epoch 184/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6850 - mae: 0.5115 - val_loss: 3.7338 - val_mae: 0.9100\n",
      "Epoch 185/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6998 - mae: 0.5192 - val_loss: 3.6783 - val_mae: 0.9076\n",
      "Epoch 186/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6958 - mae: 0.5128 - val_loss: 3.4615 - val_mae: 0.8956\n",
      "Epoch 187/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6734 - mae: 0.5111 - val_loss: 3.5565 - val_mae: 0.9048\n",
      "Epoch 188/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7024 - mae: 0.5098 - val_loss: 3.6805 - val_mae: 0.9082\n",
      "Epoch 189/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6907 - mae: 0.5094 - val_loss: 3.8159 - val_mae: 0.9150\n",
      "Epoch 190/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6569 - mae: 0.4995 - val_loss: 3.7672 - val_mae: 0.9228\n",
      "Epoch 191/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.9276 - mae: 0.6052 - val_loss: 3.6117 - val_mae: 0.8963\n",
      "Epoch 192/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7275 - mae: 0.5236 - val_loss: 3.4988 - val_mae: 0.9022\n",
      "Epoch 193/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6626 - mae: 0.4938 - val_loss: 3.6498 - val_mae: 0.9114\n",
      "Epoch 194/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6533 - mae: 0.4983 - val_loss: 3.8116 - val_mae: 0.9896\n",
      "Epoch 195/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.7403 - mae: 0.5428 - val_loss: 3.6095 - val_mae: 0.9088\n",
      "Epoch 196/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6473 - mae: 0.4905 - val_loss: 3.7043 - val_mae: 0.9213\n",
      "Epoch 197/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6994 - mae: 0.5170 - val_loss: 3.5049 - val_mae: 0.9116\n",
      "Epoch 198/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6862 - mae: 0.5081 - val_loss: 3.5237 - val_mae: 0.9221\n",
      "Epoch 199/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6851 - mae: 0.5070 - val_loss: 3.4705 - val_mae: 0.9018\n",
      "Epoch 200/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6567 - mae: 0.5007 - val_loss: 3.6740 - val_mae: 0.9040\n",
      "Epoch 201/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6638 - mae: 0.4986 - val_loss: 3.5312 - val_mae: 0.9076\n",
      "Epoch 202/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6722 - mae: 0.5077 - val_loss: 3.6294 - val_mae: 0.9089\n",
      "Epoch 203/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6602 - mae: 0.4961 - val_loss: 3.6411 - val_mae: 0.9227\n",
      "Epoch 204/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6958 - mae: 0.5103 - val_loss: 3.5336 - val_mae: 0.8995\n",
      "Epoch 205/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6588 - mae: 0.4951 - val_loss: 3.4303 - val_mae: 0.9060\n",
      "Epoch 206/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7003 - mae: 0.5201 - val_loss: 3.5526 - val_mae: 0.8938\n",
      "Epoch 207/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6594 - mae: 0.4968 - val_loss: 3.4952 - val_mae: 0.9277\n",
      "Epoch 208/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6643 - mae: 0.5005 - val_loss: 3.4131 - val_mae: 0.9182\n",
      "Epoch 209/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7185 - mae: 0.5216 - val_loss: 3.6762 - val_mae: 0.9330\n",
      "Epoch 210/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7671 - mae: 0.5515 - val_loss: 3.4819 - val_mae: 0.9030\n",
      "Epoch 211/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6478 - mae: 0.4959 - val_loss: 3.5874 - val_mae: 0.9061\n",
      "Epoch 212/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6855 - mae: 0.5091 - val_loss: 3.4598 - val_mae: 0.9026\n",
      "Epoch 213/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6810 - mae: 0.5049 - val_loss: 3.5112 - val_mae: 0.9172\n",
      "Epoch 214/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6665 - mae: 0.4986 - val_loss: 3.6716 - val_mae: 0.9547\n",
      "Epoch 215/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6682 - mae: 0.5032 - val_loss: 3.5064 - val_mae: 0.9256\n",
      "Epoch 216/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6813 - mae: 0.5083 - val_loss: 3.3890 - val_mae: 0.9184\n",
      "Epoch 217/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6612 - mae: 0.5037 - val_loss: 3.3647 - val_mae: 0.8897\n",
      "Epoch 218/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6527 - mae: 0.4994 - val_loss: 3.4510 - val_mae: 0.8996\n",
      "Epoch 219/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6501 - mae: 0.4894 - val_loss: 3.4998 - val_mae: 0.9031\n",
      "Epoch 220/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6311 - mae: 0.4839 - val_loss: 3.5206 - val_mae: 0.9219\n",
      "Epoch 221/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7110 - mae: 0.5243 - val_loss: 3.5144 - val_mae: 0.9045\n",
      "Epoch 222/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6382 - mae: 0.4897 - val_loss: 3.7493 - val_mae: 0.9407\n",
      "Epoch 223/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6974 - mae: 0.5234 - val_loss: 3.5118 - val_mae: 0.9151\n",
      "Epoch 224/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.0395 - mae: 0.6099 - val_loss: 3.7148 - val_mae: 0.9245\n",
      "Epoch 225/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6913 - mae: 0.5140 - val_loss: 3.5242 - val_mae: 0.8988\n",
      "Epoch 226/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6385 - mae: 0.4889 - val_loss: 3.6291 - val_mae: 0.9313\n",
      "Epoch 227/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6502 - mae: 0.4937 - val_loss: 3.5656 - val_mae: 0.9291\n",
      "Epoch 228/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6571 - mae: 0.4939 - val_loss: 3.5595 - val_mae: 0.9072\n",
      "Epoch 229/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6186 - mae: 0.4824 - val_loss: 3.5494 - val_mae: 0.9170\n",
      "Epoch 230/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6206 - mae: 0.4791 - val_loss: 3.4758 - val_mae: 0.9001\n",
      "Epoch 231/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6268 - mae: 0.4820 - val_loss: 3.4953 - val_mae: 0.9116\n",
      "Epoch 232/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6354 - mae: 0.4868 - val_loss: 3.6202 - val_mae: 0.9224\n",
      "Epoch 233/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6198 - mae: 0.4818 - val_loss: 3.4198 - val_mae: 0.9073\n",
      "Epoch 234/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6440 - mae: 0.4935 - val_loss: 3.6664 - val_mae: 0.9198\n",
      "Epoch 235/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6507 - mae: 0.4954 - val_loss: 3.6414 - val_mae: 0.9144\n",
      "Epoch 236/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6747 - mae: 0.5077 - val_loss: 4.0995 - val_mae: 0.9550\n",
      "Epoch 237/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7555 - mae: 0.5415 - val_loss: 3.5053 - val_mae: 0.9141\n",
      "Epoch 238/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6784 - mae: 0.5006 - val_loss: 3.6077 - val_mae: 0.9222\n",
      "Epoch 239/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6737 - mae: 0.5122 - val_loss: 3.5979 - val_mae: 0.9218\n",
      "Epoch 240/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6309 - mae: 0.4804 - val_loss: 3.6631 - val_mae: 0.9117\n",
      "Epoch 241/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6368 - mae: 0.4849 - val_loss: 3.5881 - val_mae: 0.9202\n",
      "Epoch 242/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6112 - mae: 0.4883 - val_loss: 3.6670 - val_mae: 0.9184\n",
      "Epoch 243/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6152 - mae: 0.4803 - val_loss: 3.3282 - val_mae: 0.9051\n",
      "Epoch 244/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6646 - mae: 0.4946 - val_loss: 3.5810 - val_mae: 0.9244\n",
      "Epoch 245/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6575 - mae: 0.4893 - val_loss: 3.7527 - val_mae: 0.9309\n",
      "Epoch 246/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6442 - mae: 0.4931 - val_loss: 3.5603 - val_mae: 0.9230\n",
      "Epoch 247/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6340 - mae: 0.4875 - val_loss: 3.5894 - val_mae: 0.8910\n",
      "Epoch 248/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6170 - mae: 0.4816 - val_loss: 3.5346 - val_mae: 0.8993\n",
      "Epoch 249/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6386 - mae: 0.4859 - val_loss: 3.5599 - val_mae: 0.9105\n",
      "Epoch 250/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6284 - mae: 0.4854 - val_loss: 3.4332 - val_mae: 0.9148\n",
      "Epoch 251/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6581 - mae: 0.4966 - val_loss: 3.6434 - val_mae: 0.9183\n",
      "Epoch 252/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6296 - mae: 0.4889 - val_loss: 3.6082 - val_mae: 0.9270\n",
      "Epoch 253/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6722 - mae: 0.5024 - val_loss: 3.4846 - val_mae: 0.9152\n",
      "Epoch 254/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6336 - mae: 0.4889 - val_loss: 3.4638 - val_mae: 0.9205\n",
      "Epoch 255/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6262 - mae: 0.4833 - val_loss: 3.7506 - val_mae: 0.9350\n",
      "Epoch 256/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6405 - mae: 0.4949 - val_loss: 3.5169 - val_mae: 0.9225\n",
      "Epoch 257/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7212 - mae: 0.5244 - val_loss: 3.6901 - val_mae: 0.9330\n",
      "Epoch 258/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6505 - mae: 0.5017 - val_loss: 3.7089 - val_mae: 0.9256\n",
      "Epoch 259/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.8769 - mae: 0.5645 - val_loss: 3.4060 - val_mae: 0.9002\n",
      "Epoch 260/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6297 - mae: 0.4903 - val_loss: 3.5240 - val_mae: 0.9240\n",
      "Epoch 261/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6536 - mae: 0.4987 - val_loss: 3.6772 - val_mae: 0.9324\n",
      "Epoch 262/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7450 - mae: 0.5253 - val_loss: 3.5098 - val_mae: 0.9078\n",
      "Epoch 263/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6137 - mae: 0.4795 - val_loss: 3.5604 - val_mae: 0.9131\n",
      "Epoch 264/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7100 - mae: 0.5231 - val_loss: 3.5639 - val_mae: 0.9228\n",
      "Epoch 265/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6170 - mae: 0.4851 - val_loss: 3.6261 - val_mae: 0.9175\n",
      "Epoch 266/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5917 - mae: 0.4712 - val_loss: 3.5413 - val_mae: 0.9058\n",
      "Epoch 267/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6022 - mae: 0.4684 - val_loss: 3.4923 - val_mae: 0.9151\n",
      "Epoch 268/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5933 - mae: 0.4715 - val_loss: 3.7643 - val_mae: 0.9298\n",
      "Epoch 269/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6343 - mae: 0.4883 - val_loss: 3.9351 - val_mae: 0.9368\n",
      "Epoch 270/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6456 - mae: 0.4944 - val_loss: 3.5180 - val_mae: 0.9452\n",
      "Epoch 271/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5973 - mae: 0.4713 - val_loss: 3.6465 - val_mae: 0.9560\n",
      "Epoch 272/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6139 - mae: 0.4848 - val_loss: 3.6817 - val_mae: 0.9387\n",
      "Epoch 273/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6125 - mae: 0.4766 - val_loss: 3.7120 - val_mae: 0.9419\n",
      "Epoch 274/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6190 - mae: 0.4893 - val_loss: 3.5788 - val_mae: 0.9482\n",
      "Epoch 275/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6756 - mae: 0.5051 - val_loss: 3.5593 - val_mae: 0.9222\n",
      "Epoch 276/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6254 - mae: 0.4814 - val_loss: 3.6762 - val_mae: 0.9320\n",
      "Epoch 277/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6024 - mae: 0.4784 - val_loss: 3.7150 - val_mae: 0.9324\n",
      "Epoch 278/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6423 - mae: 0.4925 - val_loss: 3.4734 - val_mae: 0.9199\n",
      "Epoch 279/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6044 - mae: 0.4776 - val_loss: 3.5957 - val_mae: 0.9358\n",
      "Epoch 280/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7072 - mae: 0.5158 - val_loss: 3.6055 - val_mae: 0.9210\n",
      "Epoch 281/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6024 - mae: 0.4722 - val_loss: 3.6719 - val_mae: 0.9270\n",
      "Epoch 282/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6061 - mae: 0.4806 - val_loss: 3.6993 - val_mae: 0.9424\n",
      "Epoch 283/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6043 - mae: 0.4844 - val_loss: 3.6935 - val_mae: 0.9304\n",
      "Epoch 284/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5831 - mae: 0.4654 - val_loss: 3.5731 - val_mae: 0.9383\n",
      "Epoch 285/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6074 - mae: 0.4738 - val_loss: 3.7117 - val_mae: 0.9401\n",
      "Epoch 286/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6575 - mae: 0.4934 - val_loss: 3.6420 - val_mae: 0.9279\n",
      "Epoch 287/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7699 - mae: 0.5406 - val_loss: 3.7961 - val_mae: 0.9340\n",
      "Epoch 288/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6689 - mae: 0.4990 - val_loss: 3.6717 - val_mae: 0.9267\n",
      "Epoch 289/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5894 - mae: 0.4680 - val_loss: 3.6599 - val_mae: 0.9492\n",
      "Epoch 290/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6267 - mae: 0.4877 - val_loss: 3.6063 - val_mae: 0.9535\n",
      "Epoch 291/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6974 - mae: 0.5237 - val_loss: 3.7218 - val_mae: 0.9318\n",
      "Epoch 292/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6906 - mae: 0.4864 - val_loss: 3.5320 - val_mae: 0.9266\n",
      "Epoch 293/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5775 - mae: 0.4617 - val_loss: 3.5802 - val_mae: 0.9380\n",
      "Epoch 294/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6085 - mae: 0.4761 - val_loss: 3.5266 - val_mae: 0.9121\n",
      "Epoch 295/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6249 - mae: 0.4851 - val_loss: 3.7041 - val_mae: 0.9417\n",
      "Epoch 296/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6264 - mae: 0.4857 - val_loss: 3.7037 - val_mae: 0.9345\n",
      "Epoch 297/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6101 - mae: 0.4796 - val_loss: 3.6654 - val_mae: 0.9237\n",
      "Epoch 298/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6007 - mae: 0.4697 - val_loss: 3.6454 - val_mae: 0.9283\n",
      "Epoch 299/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6674 - mae: 0.5003 - val_loss: 3.5894 - val_mae: 0.9275\n",
      "Epoch 300/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6324 - mae: 0.4911 - val_loss: 3.6663 - val_mae: 0.9489\n",
      "Epoch 301/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5939 - mae: 0.4730 - val_loss: 3.5072 - val_mae: 0.9201\n",
      "Epoch 302/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7045 - mae: 0.5144 - val_loss: 3.4470 - val_mae: 0.9304\n",
      "Epoch 303/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5902 - mae: 0.4722 - val_loss: 3.5586 - val_mae: 0.9224\n",
      "Epoch 304/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5801 - mae: 0.4658 - val_loss: 3.5783 - val_mae: 0.9331\n",
      "Epoch 305/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6053 - mae: 0.4777 - val_loss: 3.6830 - val_mae: 0.9253\n",
      "Epoch 306/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5987 - mae: 0.4674 - val_loss: 3.5580 - val_mae: 0.9128\n",
      "Epoch 307/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6169 - mae: 0.4768 - val_loss: 3.6362 - val_mae: 0.9283\n",
      "Epoch 308/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5596 - mae: 0.4557 - val_loss: 3.4765 - val_mae: 0.9255\n",
      "Epoch 309/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6012 - mae: 0.4773 - val_loss: 3.6018 - val_mae: 0.9443\n",
      "Epoch 310/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5943 - mae: 0.4731 - val_loss: 3.7741 - val_mae: 0.9665\n",
      "Epoch 311/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6237 - mae: 0.4842 - val_loss: 3.5339 - val_mae: 0.9299\n",
      "Epoch 312/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6005 - mae: 0.4704 - val_loss: 3.4120 - val_mae: 0.9268\n",
      "Epoch 313/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6181 - mae: 0.4804 - val_loss: 3.5758 - val_mae: 0.9300\n",
      "Epoch 314/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7354 - mae: 0.5245 - val_loss: 3.6957 - val_mae: 0.9429\n",
      "Epoch 315/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5840 - mae: 0.4687 - val_loss: 3.7368 - val_mae: 0.9302\n",
      "Epoch 316/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6235 - mae: 0.4879 - val_loss: 3.6314 - val_mae: 0.9392\n",
      "Epoch 317/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5936 - mae: 0.4750 - val_loss: 3.7039 - val_mae: 0.9232\n",
      "Epoch 318/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5685 - mae: 0.4580 - val_loss: 3.6916 - val_mae: 0.9535\n",
      "Epoch 319/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6444 - mae: 0.4949 - val_loss: 3.5433 - val_mae: 0.9271\n",
      "Epoch 320/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5818 - mae: 0.4654 - val_loss: 3.5871 - val_mae: 0.9254\n",
      "Epoch 321/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5865 - mae: 0.4657 - val_loss: 3.5107 - val_mae: 0.9152\n",
      "Epoch 322/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5689 - mae: 0.4621 - val_loss: 3.6876 - val_mae: 0.9504\n",
      "Epoch 323/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5946 - mae: 0.4762 - val_loss: 3.4928 - val_mae: 0.9213\n",
      "Epoch 324/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5609 - mae: 0.4574 - val_loss: 3.7747 - val_mae: 0.9532\n",
      "Epoch 325/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6402 - mae: 0.4875 - val_loss: 3.4862 - val_mae: 0.9403\n",
      "Epoch 326/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5937 - mae: 0.4711 - val_loss: 3.5985 - val_mae: 0.9439\n",
      "Epoch 327/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5821 - mae: 0.4626 - val_loss: 3.7698 - val_mae: 0.9368\n",
      "Epoch 328/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5635 - mae: 0.4595 - val_loss: 3.5080 - val_mae: 0.9317\n",
      "Epoch 329/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5912 - mae: 0.4649 - val_loss: 3.7586 - val_mae: 0.9445\n",
      "Epoch 330/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6054 - mae: 0.4797 - val_loss: 3.6759 - val_mae: 0.9403\n",
      "Epoch 331/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5969 - mae: 0.4707 - val_loss: 3.8405 - val_mae: 0.9425\n",
      "Epoch 332/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5895 - mae: 0.4667 - val_loss: 3.6454 - val_mae: 0.9389\n",
      "Epoch 333/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6133 - mae: 0.4737 - val_loss: 3.7009 - val_mae: 0.9393\n",
      "Epoch 334/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5706 - mae: 0.4621 - val_loss: 3.7405 - val_mae: 0.9640\n",
      "Epoch 335/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6049 - mae: 0.4747 - val_loss: 3.6930 - val_mae: 0.9478\n",
      "Epoch 336/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5957 - mae: 0.4731 - val_loss: 3.6218 - val_mae: 0.9477\n",
      "Epoch 337/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5963 - mae: 0.4694 - val_loss: 3.8494 - val_mae: 0.9498\n",
      "Epoch 338/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5681 - mae: 0.4616 - val_loss: 3.6405 - val_mae: 0.9305\n",
      "Epoch 339/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5890 - mae: 0.4696 - val_loss: 3.7519 - val_mae: 0.9660\n",
      "Epoch 340/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5749 - mae: 0.4621 - val_loss: 3.5740 - val_mae: 0.9364\n",
      "Epoch 341/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6142 - mae: 0.4817 - val_loss: 3.7310 - val_mae: 0.9330\n",
      "Epoch 342/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6045 - mae: 0.4649 - val_loss: 3.6410 - val_mae: 0.9410\n",
      "Epoch 343/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5900 - mae: 0.4700 - val_loss: 3.6928 - val_mae: 0.9532\n",
      "Epoch 344/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6398 - mae: 0.4935 - val_loss: 3.6172 - val_mae: 0.9442\n",
      "Epoch 345/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5846 - mae: 0.4647 - val_loss: 3.5174 - val_mae: 0.9298\n",
      "Epoch 346/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5649 - mae: 0.4575 - val_loss: 3.7576 - val_mae: 0.9708\n",
      "Epoch 347/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5774 - mae: 0.4612 - val_loss: 3.5679 - val_mae: 0.9359\n",
      "Epoch 348/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5707 - mae: 0.4633 - val_loss: 3.7063 - val_mae: 0.9561\n",
      "Epoch 349/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5939 - mae: 0.4733 - val_loss: 3.5265 - val_mae: 0.9333\n",
      "Epoch 350/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6848 - mae: 0.5077 - val_loss: 3.7044 - val_mae: 0.9383\n",
      "Epoch 351/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6316 - mae: 0.4837 - val_loss: 3.6017 - val_mae: 0.9319\n",
      "Epoch 352/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5910 - mae: 0.4716 - val_loss: 3.6763 - val_mae: 0.9458\n",
      "Epoch 353/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6003 - mae: 0.4794 - val_loss: 3.7278 - val_mae: 0.9359\n",
      "Epoch 354/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5689 - mae: 0.4605 - val_loss: 3.6198 - val_mae: 0.9439\n",
      "Epoch 355/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5709 - mae: 0.4575 - val_loss: 3.7371 - val_mae: 0.9519\n",
      "Epoch 356/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5821 - mae: 0.4617 - val_loss: 3.5879 - val_mae: 0.9568\n",
      "Epoch 357/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6097 - mae: 0.4767 - val_loss: 3.6669 - val_mae: 0.9339\n",
      "Epoch 358/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5643 - mae: 0.4545 - val_loss: 3.7136 - val_mae: 0.9476\n",
      "Epoch 359/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6008 - mae: 0.4748 - val_loss: 3.7921 - val_mae: 0.9511\n",
      "Epoch 360/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5620 - mae: 0.4563 - val_loss: 3.7017 - val_mae: 0.9449\n",
      "Epoch 361/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5736 - mae: 0.4584 - val_loss: 3.5706 - val_mae: 0.9540\n",
      "Epoch 362/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5854 - mae: 0.4699 - val_loss: 3.7289 - val_mae: 0.9454\n",
      "Epoch 363/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5555 - mae: 0.4501 - val_loss: 3.6640 - val_mae: 0.9640\n",
      "Epoch 364/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6719 - mae: 0.4963 - val_loss: 3.9511 - val_mae: 0.9559\n",
      "Epoch 365/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5992 - mae: 0.4749 - val_loss: 3.5807 - val_mae: 0.9356\n",
      "Epoch 366/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5608 - mae: 0.4566 - val_loss: 3.5274 - val_mae: 0.9337\n",
      "Epoch 367/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5594 - mae: 0.4516 - val_loss: 3.6797 - val_mae: 0.9766\n",
      "Epoch 368/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5976 - mae: 0.4731 - val_loss: 3.7850 - val_mae: 0.9457\n",
      "Epoch 369/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5836 - mae: 0.4633 - val_loss: 3.5822 - val_mae: 0.9423\n",
      "Epoch 370/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5563 - mae: 0.4556 - val_loss: 3.5781 - val_mae: 0.9339\n",
      "Epoch 371/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5598 - mae: 0.4541 - val_loss: 3.5199 - val_mae: 0.9493\n",
      "Epoch 372/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5638 - mae: 0.4490 - val_loss: 3.6307 - val_mae: 0.9442\n",
      "Epoch 373/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5300 - mae: 0.4423 - val_loss: 3.7306 - val_mae: 0.9486\n",
      "Epoch 374/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5648 - mae: 0.4526 - val_loss: 3.6822 - val_mae: 0.9490\n",
      "Epoch 375/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5873 - mae: 0.4628 - val_loss: 3.7654 - val_mae: 0.9694\n",
      "Epoch 376/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5765 - mae: 0.4657 - val_loss: 3.6550 - val_mae: 0.9374\n",
      "Epoch 377/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5458 - mae: 0.4459 - val_loss: 3.6802 - val_mae: 0.9427\n",
      "Epoch 378/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5876 - mae: 0.4658 - val_loss: 3.6928 - val_mae: 0.9526\n",
      "Epoch 379/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5283 - mae: 0.4434 - val_loss: 3.5935 - val_mae: 0.9431\n",
      "Epoch 380/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5299 - mae: 0.4387 - val_loss: 3.8163 - val_mae: 0.9751\n",
      "Epoch 381/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6092 - mae: 0.4796 - val_loss: 3.9819 - val_mae: 0.9709\n",
      "Epoch 382/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6334 - mae: 0.4861 - val_loss: 3.7213 - val_mae: 0.9579\n",
      "Epoch 383/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5968 - mae: 0.4677 - val_loss: 3.5546 - val_mae: 0.9447\n",
      "Epoch 384/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5822 - mae: 0.4656 - val_loss: 3.7732 - val_mae: 0.9556\n",
      "Epoch 385/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5701 - mae: 0.4585 - val_loss: 3.8282 - val_mae: 0.9715\n",
      "Epoch 386/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6504 - mae: 0.4916 - val_loss: 3.5435 - val_mae: 0.9516\n",
      "Epoch 387/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5430 - mae: 0.4485 - val_loss: 3.6658 - val_mae: 0.9464\n",
      "Epoch 388/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5904 - mae: 0.4705 - val_loss: 3.6041 - val_mae: 0.9464\n",
      "Epoch 389/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5440 - mae: 0.4491 - val_loss: 3.5466 - val_mae: 0.9431\n",
      "Epoch 390/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5600 - mae: 0.4562 - val_loss: 3.5807 - val_mae: 0.9568\n",
      "Epoch 391/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5904 - mae: 0.4714 - val_loss: 3.6126 - val_mae: 0.9519\n",
      "Epoch 392/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5684 - mae: 0.4563 - val_loss: 3.7191 - val_mae: 0.9546\n",
      "Epoch 393/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6022 - mae: 0.4771 - val_loss: 3.5252 - val_mae: 0.9436\n",
      "Epoch 394/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.7042 - mae: 0.5085 - val_loss: 3.4203 - val_mae: 0.9207\n",
      "Epoch 395/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5893 - mae: 0.4731 - val_loss: 3.7090 - val_mae: 0.9419\n",
      "Epoch 396/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5541 - mae: 0.4541 - val_loss: 3.7483 - val_mae: 0.9767\n",
      "Epoch 397/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5780 - mae: 0.4628 - val_loss: 3.7242 - val_mae: 0.9510\n",
      "Epoch 398/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5552 - mae: 0.4468 - val_loss: 3.7694 - val_mae: 0.9602\n",
      "Epoch 399/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6541 - mae: 0.5028 - val_loss: 3.8411 - val_mae: 0.9646\n",
      "Epoch 400/500\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5605 - mae: 0.4514 - val_loss: 3.6699 - val_mae: 0.9653\n",
      "Epoch 401/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5594 - mae: 0.4556 - val_loss: 3.7357 - val_mae: 0.9481\n",
      "Epoch 402/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5486 - mae: 0.4494 - val_loss: 3.7795 - val_mae: 0.9597\n",
      "Epoch 403/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6227 - mae: 0.4743 - val_loss: 3.7316 - val_mae: 0.9572\n",
      "Epoch 404/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5423 - mae: 0.4494 - val_loss: 3.5357 - val_mae: 0.9544\n",
      "Epoch 405/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5698 - mae: 0.4595 - val_loss: 3.4416 - val_mae: 0.9382\n",
      "Epoch 406/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5417 - mae: 0.4467 - val_loss: 3.5716 - val_mae: 0.9441\n",
      "Epoch 407/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5503 - mae: 0.4533 - val_loss: 3.6705 - val_mae: 0.9557\n",
      "Epoch 408/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6920 - mae: 0.4956 - val_loss: 3.6213 - val_mae: 0.9425\n",
      "Epoch 409/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5730 - mae: 0.4602 - val_loss: 3.6455 - val_mae: 0.9447\n",
      "Epoch 410/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5241 - mae: 0.4400 - val_loss: 3.6498 - val_mae: 0.9451\n",
      "Epoch 411/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5825 - mae: 0.4685 - val_loss: 3.7455 - val_mae: 0.9501\n",
      "Epoch 412/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5381 - mae: 0.4440 - val_loss: 3.7145 - val_mae: 0.9602\n",
      "Epoch 413/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5690 - mae: 0.4584 - val_loss: 3.7313 - val_mae: 0.9450\n",
      "Epoch 414/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5361 - mae: 0.4438 - val_loss: 3.6965 - val_mae: 0.9585\n",
      "Epoch 415/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6437 - mae: 0.4699 - val_loss: 3.6945 - val_mae: 0.9386\n",
      "Epoch 416/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5856 - mae: 0.4645 - val_loss: 3.6650 - val_mae: 0.9476\n",
      "Epoch 417/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5507 - mae: 0.4479 - val_loss: 3.6011 - val_mae: 0.9357\n",
      "Epoch 418/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5535 - mae: 0.4489 - val_loss: 3.5970 - val_mae: 0.9594\n",
      "Epoch 419/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5772 - mae: 0.4619 - val_loss: 3.9301 - val_mae: 1.0073\n",
      "Epoch 420/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6648 - mae: 0.4845 - val_loss: 3.7180 - val_mae: 0.9561\n",
      "Epoch 421/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5553 - mae: 0.4494 - val_loss: 3.5390 - val_mae: 0.9505\n",
      "Epoch 422/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5966 - mae: 0.4640 - val_loss: 3.6112 - val_mae: 0.9379\n",
      "Epoch 423/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5457 - mae: 0.4522 - val_loss: 3.8643 - val_mae: 0.9746\n",
      "Epoch 424/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5685 - mae: 0.4577 - val_loss: 3.7874 - val_mae: 0.9621\n",
      "Epoch 425/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5685 - mae: 0.4619 - val_loss: 3.8718 - val_mae: 0.9868\n",
      "Epoch 426/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5787 - mae: 0.4667 - val_loss: 3.5602 - val_mae: 0.9397\n",
      "Epoch 427/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5765 - mae: 0.4502 - val_loss: 3.6984 - val_mae: 0.9610\n",
      "Epoch 428/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5477 - mae: 0.4534 - val_loss: 3.6935 - val_mae: 0.9497\n",
      "Epoch 429/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5652 - mae: 0.4554 - val_loss: 3.7907 - val_mae: 0.9498\n",
      "Epoch 430/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5401 - mae: 0.4452 - val_loss: 3.6048 - val_mae: 0.9555\n",
      "Epoch 431/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5660 - mae: 0.4599 - val_loss: 3.9335 - val_mae: 0.9795\n",
      "Epoch 432/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5614 - mae: 0.4545 - val_loss: 3.6690 - val_mae: 0.9330\n",
      "Epoch 433/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5427 - mae: 0.4460 - val_loss: 3.7194 - val_mae: 0.9594\n",
      "Epoch 434/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5430 - mae: 0.4467 - val_loss: 3.7463 - val_mae: 0.9570\n",
      "Epoch 435/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5605 - mae: 0.4506 - val_loss: 3.7568 - val_mae: 0.9519\n",
      "Epoch 436/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5439 - mae: 0.4439 - val_loss: 3.8591 - val_mae: 0.9696\n",
      "Epoch 437/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5344 - mae: 0.4379 - val_loss: 3.8591 - val_mae: 0.9728\n",
      "Epoch 438/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5763 - mae: 0.4696 - val_loss: 3.9079 - val_mae: 0.9768\n",
      "Epoch 439/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5998 - mae: 0.4690 - val_loss: 3.6983 - val_mae: 0.9448\n",
      "Epoch 440/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5611 - mae: 0.4555 - val_loss: 3.9487 - val_mae: 0.9706\n",
      "Epoch 441/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5590 - mae: 0.4536 - val_loss: 3.5628 - val_mae: 0.9581\n",
      "Epoch 442/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5569 - mae: 0.4471 - val_loss: 3.6612 - val_mae: 0.9453\n",
      "Epoch 443/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6234 - mae: 0.4798 - val_loss: 3.7429 - val_mae: 0.9532\n",
      "Epoch 444/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5638 - mae: 0.4634 - val_loss: 3.7979 - val_mae: 0.9623\n",
      "Epoch 445/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6493 - mae: 0.4972 - val_loss: 3.6351 - val_mae: 0.9470\n",
      "Epoch 446/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5319 - mae: 0.4429 - val_loss: 3.7694 - val_mae: 0.9549\n",
      "Epoch 447/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5445 - mae: 0.4499 - val_loss: 3.8045 - val_mae: 0.9742\n",
      "Epoch 448/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5743 - mae: 0.4569 - val_loss: 3.7941 - val_mae: 0.9556\n",
      "Epoch 449/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5564 - mae: 0.4557 - val_loss: 3.5055 - val_mae: 0.9461\n",
      "Epoch 450/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6379 - mae: 0.4906 - val_loss: 3.7318 - val_mae: 0.9541\n",
      "Epoch 451/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5661 - mae: 0.4599 - val_loss: 3.5453 - val_mae: 0.9400\n",
      "Epoch 452/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5642 - mae: 0.4590 - val_loss: 3.6661 - val_mae: 0.9490\n",
      "Epoch 453/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5484 - mae: 0.4532 - val_loss: 3.8509 - val_mae: 0.9751\n",
      "Epoch 454/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5108 - mae: 0.4299 - val_loss: 3.7658 - val_mae: 0.9677\n",
      "Epoch 455/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5216 - mae: 0.4365 - val_loss: 3.7985 - val_mae: 0.9598\n",
      "Epoch 456/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5730 - mae: 0.4639 - val_loss: 3.6015 - val_mae: 0.9381\n",
      "Epoch 457/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5710 - mae: 0.4567 - val_loss: 3.8226 - val_mae: 0.9613\n",
      "Epoch 458/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5910 - mae: 0.4624 - val_loss: 3.7270 - val_mae: 0.9496\n",
      "Epoch 459/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5753 - mae: 0.4589 - val_loss: 3.7455 - val_mae: 0.9503\n",
      "Epoch 460/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5457 - mae: 0.4490 - val_loss: 3.6376 - val_mae: 0.9588\n",
      "Epoch 461/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5625 - mae: 0.4547 - val_loss: 3.5816 - val_mae: 0.9428\n",
      "Epoch 462/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5477 - mae: 0.4580 - val_loss: 3.6299 - val_mae: 0.9507\n",
      "Epoch 463/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5395 - mae: 0.4490 - val_loss: 3.7094 - val_mae: 0.9516\n",
      "Epoch 464/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5769 - mae: 0.4575 - val_loss: 3.7109 - val_mae: 0.9598\n",
      "Epoch 465/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.1208 - mae: 0.6305 - val_loss: 3.8207 - val_mae: 0.9670\n",
      "Epoch 466/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6209 - mae: 0.4818 - val_loss: 3.6185 - val_mae: 0.9429\n",
      "Epoch 467/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5633 - mae: 0.4488 - val_loss: 3.6954 - val_mae: 0.9660\n",
      "Epoch 468/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5452 - mae: 0.4445 - val_loss: 3.7886 - val_mae: 0.9770\n",
      "Epoch 469/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5618 - mae: 0.4639 - val_loss: 3.5815 - val_mae: 0.9429\n",
      "Epoch 470/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5246 - mae: 0.4401 - val_loss: 3.6222 - val_mae: 0.9474\n",
      "Epoch 471/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5324 - mae: 0.4367 - val_loss: 3.5870 - val_mae: 0.9419\n",
      "Epoch 472/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5158 - mae: 0.4301 - val_loss: 3.7003 - val_mae: 0.9776\n",
      "Epoch 473/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5556 - mae: 0.4473 - val_loss: 3.7610 - val_mae: 0.9545\n",
      "Epoch 474/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5706 - mae: 0.4605 - val_loss: 3.7096 - val_mae: 0.9520\n",
      "Epoch 475/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5344 - mae: 0.4445 - val_loss: 3.7401 - val_mae: 0.9608\n",
      "Epoch 476/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5438 - mae: 0.4473 - val_loss: 3.6457 - val_mae: 0.9451\n",
      "Epoch 477/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5473 - mae: 0.4408 - val_loss: 3.6561 - val_mae: 0.9547\n",
      "Epoch 478/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6249 - mae: 0.4877 - val_loss: 3.6900 - val_mae: 0.9432\n",
      "Epoch 479/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5642 - mae: 0.4528 - val_loss: 3.6759 - val_mae: 0.9571\n",
      "Epoch 480/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5212 - mae: 0.4315 - val_loss: 3.8336 - val_mae: 0.9659\n",
      "Epoch 481/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6200 - mae: 0.4852 - val_loss: 3.7141 - val_mae: 0.9616\n",
      "Epoch 482/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5580 - mae: 0.4551 - val_loss: 3.6905 - val_mae: 0.9575\n",
      "Epoch 483/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5288 - mae: 0.4422 - val_loss: 3.7367 - val_mae: 0.9565\n",
      "Epoch 484/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5426 - mae: 0.4474 - val_loss: 3.6427 - val_mae: 0.9602\n",
      "Epoch 485/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5222 - mae: 0.4385 - val_loss: 3.8153 - val_mae: 0.9683\n",
      "Epoch 486/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5314 - mae: 0.4413 - val_loss: 3.5806 - val_mae: 0.9364\n",
      "Epoch 487/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5988 - mae: 0.4684 - val_loss: 3.5813 - val_mae: 0.9464\n",
      "Epoch 488/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5755 - mae: 0.4563 - val_loss: 3.4835 - val_mae: 0.9664\n",
      "Epoch 489/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5430 - mae: 0.4468 - val_loss: 3.9608 - val_mae: 0.9775\n",
      "Epoch 490/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5386 - mae: 0.4401 - val_loss: 3.6666 - val_mae: 0.9533\n",
      "Epoch 491/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5735 - mae: 0.4576 - val_loss: 3.6783 - val_mae: 0.9514\n",
      "Epoch 492/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5291 - mae: 0.4422 - val_loss: 3.7420 - val_mae: 0.9593\n",
      "Epoch 493/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.6769 - mae: 0.4733 - val_loss: 3.6648 - val_mae: 0.9416\n",
      "Epoch 494/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5233 - mae: 0.4408 - val_loss: 3.6885 - val_mae: 0.9586\n",
      "Epoch 495/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5955 - mae: 0.4706 - val_loss: 3.6416 - val_mae: 0.9635\n",
      "Epoch 496/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5313 - mae: 0.4480 - val_loss: 3.6531 - val_mae: 0.9467\n",
      "Epoch 497/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5166 - mae: 0.4333 - val_loss: 3.6628 - val_mae: 0.9702\n",
      "Epoch 498/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5528 - mae: 0.4535 - val_loss: 3.5351 - val_mae: 0.9421\n",
      "Epoch 499/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5730 - mae: 0.4621 - val_loss: 3.6115 - val_mae: 0.9439\n",
      "Epoch 500/500\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.5521 - mae: 0.4476 - val_loss: 3.4956 - val_mae: 0.9363\n"
     ]
    }
   ],
   "source": [
    "val_features_dict = {name: np.array(value) \r\n",
    "                         for name, value in val.items()}\r\n",
    "history_1 = housePrices_model.fit(x=housePrices_features_dict, y=housePrices_labels,epochs=500,\r\n",
    "                        validation_data=(val_features_dict, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "v52vc1fw49Um",
    "outputId": "df5f4302-0d0a-4981-f9ac-26b92d679e7b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a graph of the loss, which is the distance between\r\n",
    "# the predicted and actual values during training and validation.\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "train_loss = history_1.history['mae']\r\n",
    "val_loss = history_1.history['mae']\r\n",
    "epochs = range(1, len(train_loss) + 1)\r\n",
    "\r\n",
    "plt.plot(epochs, train_loss, 'g.', label='Training loss')\r\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
    "plt.title('Training and validation loss')\r\n",
    "plt.xlabel('Epochs')\r\n",
    "plt.ylabel('Loss')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Exclude the first few epochs so the graph is easier to read\r\n",
    "SKIP = 20\r\n",
    "\r\n",
    "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\r\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\r\n",
    "plt.title('Training and validation loss')\r\n",
    "plt.xlabel('Epochs')\r\n",
    "plt.ylabel('Loss')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxgJarZk3bfH"
   },
   "source": [
    "Since the preprocessing is part of the model, you can save the model and reload it somewhere else and get identical results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ay-8ymNA2ZCh",
    "outputId": "79710048-a899-4003-ca73-270ae4d0ed9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    }
   ],
   "source": [
    "housePrices_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm6jMTpD20lK",
    "outputId": "f177c2e9-3101-4658-c4b0-3f2c2bf194c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.27]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[1.27]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in housePrices_features_dict.items()}\n",
    "\n",
    "before = housePrices_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLOZuDVtNIow",
    "outputId": "a3da7450-1b10-4168-bccf-71c5056604ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.208]\n",
      " [3.883]\n",
      " [4.605]\n",
      " [3.381]\n",
      " [4.524]]\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "\r\n",
    "houseData_own2 = {'Type': np.array(['SFH', 'SFH', 'SFH', 'Condo', 'SFH']),\r\n",
    "  'houseEra': np.array(['20A', '19A', '20A', '20A', '20A']),\r\n",
    "\t'Area': np.array([8410, 1400, 1500, 1500, 1500]),\r\n",
    "  'Zip': np.array(['60062', '60062', '60076', '60076', '60076']),\r\n",
    "\t'Rooms': np.array([16, 6, 7, 7, 7]),\r\n",
    "  'FullBaths': np.array([2.0, 2.0, 2.0, 2.5, 2.5]),\r\n",
    "  'HalfBaths': np.array([0.0, 1.0, 1.0, 0.0, 0.0]),\r\n",
    "  'BsmtBth': np.array(['Yes', 'No', 'No', 'No', 'No']),\r\n",
    "  'Beds': np.array([5, 3, 3, 3, 3]),\r\n",
    "  'BsmtBeds': np.array([1.0, 0.0, 0.0, 0.0, 0.0]),\r\n",
    "  'GarageSpaces': np.array([3, 2, 0, 0, 0])  }\r\n",
    "\r\n",
    "ans = reloaded.predict(houseData_own2)\r\n",
    "\r\n",
    "print(ans)\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "history_visible": true,
   "name": "Copy of Copy of csv.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
